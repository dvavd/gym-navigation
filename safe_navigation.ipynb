{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PPOLag.yaml from /Users/davidstreuli/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/utils/../configs/on-policy/PPOLag.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Logging data to .</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/runs/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">PPOLag-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">{NavigationTrackSafe-v0}</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/seed-000-2025-04-03-14-55-11/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">progress.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mLogging data to .\u001b[0m\u001b[1;35m/runs/\u001b[0m\u001b[1;95mPPOLag-\u001b[0m\u001b[1;36m{\u001b[0m\u001b[1;36mNavigationTrackSafe-v0\u001b[0m\u001b[1;36m}\u001b[0m\u001b[1;35m/seed-000-2025-04-03-14-55-11/\u001b[0m\u001b[1;95mprogress.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Save with config in config.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mSave with config in config.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">INFO: Start training</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mINFO: Start training\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/davidstreuli/anaconda3/envs/omnisafe/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/davidstreuli/anaconda3/envs/omnisafe/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid action [ 0.5424968 -1.2879812] (<class 'numpy.ndarray'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m env_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNavigationTrackSafe-v0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m agent \u001b[38;5;241m=\u001b[39m omnisafe\u001b[38;5;241m.\u001b[39mAgent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPOLag\u001b[39m\u001b[38;5;124m'\u001b[39m, env_id, custom_cfgs\u001b[38;5;241m=\u001b[39mcustom_cfgs)\n\u001b[0;32m---> 25\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/algorithms/algo_wrapper.py:178\u001b[0m, in \u001b[0;36mAlgoWrapper.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Agent learning.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m        ep_len: The episode length of the final episode.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     ep_ret, ep_cost, ep_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_statistical_tools()\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ep_ret, ep_cost, ep_len\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/algorithms/on_policy/base/policy_gradient.py:250\u001b[0m, in \u001b[0;36mPolicyGradient.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    249\u001b[0m rollout_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_critic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mstore({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime/Rollout\u001b[39m\u001b[38;5;124m'\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m rollout_time})\n\u001b[1;32m    258\u001b[0m update_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/adapter/onpolicy_adapter.py:86\u001b[0m, in \u001b[0;36mOnPolicyAdapter.rollout\u001b[0;34m(self, steps_per_epoch, agent, buffer, logger)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m track(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mrange\u001b[39m(steps_per_epoch),\n\u001b[1;32m     83\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing rollout for epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogger\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     84\u001b[0m ):\n\u001b[1;32m     85\u001b[0m     act, value_r, value_c, logp \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mstep(obs)\n\u001b[0;32m---> 86\u001b[0m     next_obs, reward, cost, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_value(reward\u001b[38;5;241m=\u001b[39mreward, cost\u001b[38;5;241m=\u001b[39mcost, info\u001b[38;5;241m=\u001b[39minfo)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfgs\u001b[38;5;241m.\u001b[39malgo_cfgs\u001b[38;5;241m.\u001b[39muse_cost:\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/adapter/online_adapter.py:182\u001b[0m, in \u001b[0;36mOnlineAdapter.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    160\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    168\u001b[0m ]:\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/wrapper.py:618\u001b[0m, in \u001b[0;36mUnsqueeze.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    617\u001b[0m action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 618\u001b[0m obs, reward, cost, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m obs, reward, cost, terminated, truncated \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    620\u001b[0m     x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (obs, reward, cost, terminated, truncated)\n\u001b[1;32m    621\u001b[0m )\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/core.py:240\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    218\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    226\u001b[0m ]:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/wrapper.py:514\u001b[0m, in \u001b[0;36mActionScale.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m.. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_old_min_action \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_old_max_action \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_old_min_action) \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m    511\u001b[0m     action \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_action\n\u001b[1;32m    512\u001b[0m ) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_action \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_action)\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/core.py:240\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    218\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    226\u001b[0m ]:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/wrapper.py:231\u001b[0m, in \u001b[0;36mObsNormalize.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    206\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    214\u001b[0m ]:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     obs, reward, cost, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_observation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m info:\n\u001b[1;32m    233\u001b[0m         final_obs_slice \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_final_observation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/core.py:240\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    218\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    226\u001b[0m ]:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/wrapper.py:161\u001b[0m, in \u001b[0;36mAutoReset.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    142\u001b[0m ]:\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     obs, reward, cost, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[1;32m    164\u001b[0m         new_obs, new_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/core.py:240\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    218\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    226\u001b[0m ]:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/wrapper.py:103\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     86\u001b[0m ]:\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     obs, reward, cost, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    106\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_limit,\n\u001b[1;32m    108\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m    109\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device,\n\u001b[1;32m    110\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/omnisafe/lib/python3.10/site-packages/omnisafe/envs/core.py:240\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    218\u001b[0m     action: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    226\u001b[0m ]:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run one timestep of the environment's dynamics using the agent actions.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m        info: Some information logged by the environment.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gym-navigation/gym_navigation/envs/navigation_track_safe.py:78\u001b[0m, in \u001b[0;36mNavigationTrackSafe.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# convert incoming action from torch to numpy for the parent\u001b[39;00m\n\u001b[1;32m     76\u001b[0m action_np \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 78\u001b[0m obs_np, reward_np, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m cost_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_distance_cost()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# convert everything to torch tensors for omnisafe\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gym-navigation/gym_navigation/envs/navigation.py:55\u001b[0m, in \u001b[0;36mNavigation.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mcontains(action):\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid action \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(action)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_perform_action(action)\n\u001b[1;32m     58\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_observation()\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid action [ 0.5424968 -1.2879812] (<class 'numpy.ndarray'>)"
     ]
    }
   ],
   "source": [
    "import omnisafe\n",
    "from gym_navigation.envs.navigation_track_safe import NavigationTrackSafe\n",
    "\n",
    "\n",
    "custom_cfgs = {\n",
    "    'model_cfgs': {\n",
    "        'actor_type': 'gaussian_learning'\n",
    "    },\n",
    "    'train_cfgs': {\n",
    "        'total_steps': 1024000,\n",
    "        'vector_env_nums': 1,\n",
    "        'parallel': 1,\n",
    "    },\n",
    "    'algo_cfgs': {\n",
    "        'steps_per_epoch': 2048,\n",
    "        'update_iters': 1,\n",
    "    },\n",
    "    'logger_cfgs': {\n",
    "        'use_wandb': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "env_id = 'NavigationTrackSafe-v0'\n",
    "agent = omnisafe.Agent('PPOLag', env_id, custom_cfgs=custom_cfgs)\n",
    "agent.learn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
